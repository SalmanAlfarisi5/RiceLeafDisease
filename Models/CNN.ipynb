{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "822d03e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf          \n",
    "import pathlib\n",
    "import re\n",
    "import numpy as np \n",
    "\n",
    "from keras import layers as L                   \n",
    "from keras.applications import MobileNetV2      \n",
    "from keras.applications.mobilenet_v2 import (\n",
    "    preprocess_input,                           \n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9df877c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train images: 692, Test images: 170\n"
     ]
    }
   ],
   "source": [
    "DATA_ROOT   = pathlib.Path(\"../Datasets\")          # <- adjust if needed\n",
    "IMG_SIZE    = (224, 224)                        # images are 224×224×3\n",
    "BATCH_SIZE  = 32\n",
    "EPOCHS      = 15\n",
    "SEED        = 42\n",
    "\n",
    "# --- 1. Collect file paths ----------------------------------------------------\n",
    "train_files, train_labels = [], []\n",
    "test_files , test_labels  = [], []\n",
    "\n",
    "class_names = sorted([p.name for p in DATA_ROOT.iterdir() if p.is_dir()])\n",
    "class_to_idx = {c: i for i, c in enumerate(class_names)}\n",
    "\n",
    "pattern = re.compile(r\"(\\d+)\\.(jpg|jpeg|png)$\", re.IGNORECASE)\n",
    "\n",
    "for cls in class_names:\n",
    "    for fp in (DATA_ROOT / cls).iterdir():\n",
    "        m = pattern.search(fp.name)\n",
    "        if not m:                    # skip non-image files\n",
    "            continue\n",
    "        idx = int(m.group(1))\n",
    "        target = test_files if idx % 5 == 0 else train_files\n",
    "        labels = test_labels if idx % 5 == 0 else train_labels\n",
    "        target.append(str(fp))\n",
    "        labels.append(class_to_idx[cls])\n",
    "\n",
    "print(f\"Train images: {len(train_files)}, Test images: {len(test_files)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "62cdcf47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Build tf.data datasets ------------------------------------------------\n",
    "def make_ds(paths, labels, training=False):\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "\n",
    "    def _load(f, y):\n",
    "        img = tf.io.read_file(f)\n",
    "        img = tf.image.decode_image(img, channels=3, expand_animations=False)\n",
    "        img = tf.image.resize(img, IMG_SIZE)\n",
    "        img = preprocess_input(img)            # MobileNetV2 preprocessing\n",
    "        return img, tf.one_hot(y, len(class_names))\n",
    "\n",
    "    ds = ds.map(_load, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    if training:\n",
    "        aug = tf.keras.Sequential([\n",
    "            L.RandomFlip(\"horizontal\"),\n",
    "            L.RandomRotation(0.05),\n",
    "            L.RandomZoom(0.1)\n",
    "        ])\n",
    "        ds = ds.map(lambda x, y: (aug(x, training=True), y),\n",
    "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
    "        ds = ds.shuffle(1024, seed=SEED)\n",
    "    return ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "train_ds = make_ds(train_files, train_labels, training=True)\n",
    "test_ds  = make_ds(test_files , test_labels , training=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c9554708",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/mobilenet_v2/mobilenet_v2_weights_tf_dim_ordering_tf_kernels_1.0_224_no_top.h5\n",
      "\u001b[1m9406464/9406464\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    }
   ],
   "source": [
    "# --- 3. Build & compile the model --------------------------------------------\n",
    "base = MobileNetV2(input_shape=IMG_SIZE + (3,), weights=\"imagenet\",\n",
    "                   include_top=False)\n",
    "base.trainable = False                       # first train only the head\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    base,\n",
    "    L.GlobalAveragePooling2D(),\n",
    "    L.Dropout(0.25),\n",
    "    L.Dense(len(class_names), activation=\"softmax\")\n",
    "])\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-3),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4f81ed0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750432736.901079   13489 service.cc:146] XLA service 0x7af3b00029f0 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1750432736.901099   13489 service.cc:154]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Ti, Compute Capability 8.6\n",
      "2025-06-20 23:18:56.956298: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2025-06-20 23:18:57.259907: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:531] Loaded cuDNN version 90501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m11/22\u001b[0m \u001b[32m━━━━━━━━━━\u001b[0m\u001b[37m━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3124 - loss: 1.8367"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1750432741.172332   13489 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 166ms/step - accuracy: 0.3783 - loss: 1.6724"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:19:05.797363: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1179', 100 bytes spill stores, 100 bytes spill loads\n",
      "\n",
      "2025-06-20 23:19:05.852269: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1179', 340 bytes spill stores, 340 bytes spill loads\n",
      "\n",
      "2025-06-20 23:19:07.229623: I external/local_xla/xla/stream_executor/cuda/cuda_asm_compiler.cc:393] ptxas warning : Registers are spilled to local memory in function 'gemm_fusion_dot_1179', 60 bytes spill stores, 60 bytes spill loads\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 405ms/step - accuracy: 0.3825 - loss: 1.6613 - val_accuracy: 0.7059 - val_loss: 0.8630\n",
      "Epoch 2/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.6565 - loss: 0.8835 - val_accuracy: 0.7824 - val_loss: 0.6045\n",
      "Epoch 3/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8037 - loss: 0.5369 - val_accuracy: 0.8353 - val_loss: 0.5081\n",
      "Epoch 4/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8173 - loss: 0.5388 - val_accuracy: 0.8471 - val_loss: 0.4653\n",
      "Epoch 5/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8488 - loss: 0.4506 - val_accuracy: 0.8529 - val_loss: 0.4116\n",
      "Epoch 6/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8928 - loss: 0.3661 - val_accuracy: 0.8941 - val_loss: 0.3978\n",
      "Epoch 7/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8782 - loss: 0.3751 - val_accuracy: 0.9059 - val_loss: 0.3607\n",
      "Epoch 8/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9101 - loss: 0.2935 - val_accuracy: 0.9059 - val_loss: 0.3323\n",
      "Epoch 9/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9173 - loss: 0.2786 - val_accuracy: 0.9059 - val_loss: 0.2998\n",
      "Epoch 10/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9016 - loss: 0.2908 - val_accuracy: 0.9000 - val_loss: 0.2980\n",
      "Epoch 11/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9376 - loss: 0.2368 - val_accuracy: 0.9000 - val_loss: 0.2872\n",
      "Epoch 12/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9474 - loss: 0.2126 - val_accuracy: 0.9000 - val_loss: 0.2874\n",
      "Epoch 13/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9369 - loss: 0.2223 - val_accuracy: 0.9118 - val_loss: 0.2572\n",
      "Epoch 14/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9310 - loss: 0.2180 - val_accuracy: 0.9176 - val_loss: 0.2326\n",
      "Epoch 15/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9551 - loss: 0.1617 - val_accuracy: 0.9059 - val_loss: 0.2569\n"
     ]
    }
   ],
   "source": [
    "# --- 4. Train (head only) -----------------------------------------------------\n",
    "hist = model.fit(train_ds,\n",
    "                 epochs=EPOCHS,\n",
    "                 validation_data=test_ds,\n",
    "                 callbacks=[\n",
    "                     tf.keras.callbacks.EarlyStopping(patience=3,\n",
    "                                                     restore_best_weights=True)\n",
    "                 ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a30d6cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 248ms/step - accuracy: 0.8684 - loss: 0.4016 - val_accuracy: 0.8882 - val_loss: 0.3625\n",
      "Epoch 2/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9561 - loss: 0.1580 - val_accuracy: 0.9000 - val_loss: 0.3140\n",
      "Epoch 3/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9826 - loss: 0.0825 - val_accuracy: 0.8882 - val_loss: 0.3180\n",
      "Epoch 4/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9849 - loss: 0.0701 - val_accuracy: 0.9059 - val_loss: 0.3051\n",
      "Epoch 5/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9936 - loss: 0.0460 - val_accuracy: 0.8941 - val_loss: 0.3239\n",
      "Epoch 6/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9878 - loss: 0.0483 - val_accuracy: 0.9000 - val_loss: 0.2610\n",
      "Epoch 7/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9931 - loss: 0.0377 - val_accuracy: 0.9353 - val_loss: 0.2135\n",
      "Epoch 8/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 1.0000 - loss: 0.0255 - val_accuracy: 0.9353 - val_loss: 0.1980\n",
      "Epoch 9/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9919 - loss: 0.0246 - val_accuracy: 0.9294 - val_loss: 0.2271\n",
      "Epoch 10/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9980 - loss: 0.0284 - val_accuracy: 0.9529 - val_loss: 0.1751\n",
      "Epoch 11/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9991 - loss: 0.0221 - val_accuracy: 0.9647 - val_loss: 0.1393\n",
      "Epoch 12/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9988 - loss: 0.0131 - val_accuracy: 0.9647 - val_loss: 0.1201\n",
      "Epoch 13/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9984 - loss: 0.0139 - val_accuracy: 0.9588 - val_loss: 0.1358\n",
      "Epoch 14/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 1.0000 - loss: 0.0072 - val_accuracy: 0.9529 - val_loss: 0.1327\n",
      "Epoch 15/15\n",
      "\u001b[1m22/22\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9994 - loss: 0.0129 - val_accuracy: 0.9706 - val_loss: 0.0941\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x7af478591720>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 5. Optional fine-tuning ---------------------------------------------------\n",
    "base.trainable = True\n",
    "for layer in base.layers[:-20]:              # unfreeze last ~20 layers only\n",
    "    layer.trainable = False\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "              loss=\"categorical_crossentropy\",\n",
    "              metrics=[\"accuracy\"])\n",
    "model.fit(train_ds,\n",
    "          epochs=EPOCHS,\n",
    "          validation_data=test_ds,\n",
    "          callbacks=[\n",
    "              tf.keras.callbacks.EarlyStopping(patience=3,\n",
    "                                               restore_best_weights=True)\n",
    "          ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9a550cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0000 00:00:1750432792.091046   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.104512   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.105091   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.105655   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.106195   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.106742   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.107296   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.107836   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.109722   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.110518   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.111078   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.111654   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.112227   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.112797   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.113368   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.113942   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.114593   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.115148   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.115741   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.116317   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.116929   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.117499   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.118069   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.118642   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.119218   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.119814   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.120439   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n",
      "W0000 00:00:1750432792.121056   12795 gpu_timer.cc:114] Skipping the delay kernel, measurement accuracy will be reduced\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mis-classified samples (truth -> pred):\n",
      "../Datasets/Bacterial_Leaf_Blight/15.jpeg : Bacterial_Leaf_Blight → Neck_Blast\n",
      "../Datasets/False_Smut/60.jpeg : False_Smut → Neck_Blast\n",
      "../Datasets/False_Smut/90.jpeg : False_Smut → Healthy\n",
      "../Datasets/False_Smut/80.jpeg : False_Smut → Neck_Blast\n",
      "../Datasets/Healthy/45.jpeg : Healthy → Brown_Spot\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-06-20 23:19:59.899954: I tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: OUT_OF_RANGE: End of sequence\n"
     ]
    }
   ],
   "source": [
    "# --- 6. Inspect mis-classifications ------------------------------------------\n",
    "y_true, y_pred, file_paths = [], [], []\n",
    "\n",
    "for (x, y), paths in zip(test_ds.unbatch(), np.array(test_files)):\n",
    "    logits = model(tf.expand_dims(x, 0), training=False)\n",
    "    y_true.append(tf.argmax(y).numpy())\n",
    "    y_pred.append(tf.argmax(logits, axis=1).numpy()[0])\n",
    "    file_paths.append(paths)\n",
    "\n",
    "mis_idx = [i for i, (t, p) in enumerate(zip(y_true, y_pred)) if t != p]\n",
    "print(\"\\nMis-classified samples (truth -> pred):\")\n",
    "for i in mis_idx:\n",
    "    print(f\"{file_paths[i]} : {class_names[y_true[i]]} → {class_names[y_pred[i]]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
